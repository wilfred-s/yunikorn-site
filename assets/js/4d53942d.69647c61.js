"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3090],{3905:function(e,n,t){t.d(n,{Zo:function(){return u},kt:function(){return d}});var r=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=r.createContext({}),p=function(e){var n=r.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},u=function(e){var n=p(e.components);return r.createElement(s.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},m=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),m=p(t),d=a,f=m["".concat(s,".").concat(d)]||m[d]||c[d]||o;return t?r.createElement(f,i(i({ref:n},u),{},{components:t})):r.createElement(f,i({ref:n},u))}));function d(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=m;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var p=2;p<o;p++)i[p]=t[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}m.displayName="MDXCreateElement"},16006:function(e,n,t){t.r(n),t.d(n,{assets:function(){return u},contentTitle:function(){return s},default:function(){return d},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return c}});var r=t(87462),a=t(63366),o=(t(67294),t(3905)),i=["components"],l={id:"run_tf",title:"Run TensorFlow Jobs",description:"How to run TensorFlow jobs with YuniKorn",keywords:["tensorflow"]},s=void 0,p={unversionedId:"user_guide/workloads/run_tf",id:"user_guide/workloads/run_tf",title:"Run TensorFlow Jobs",description:"How to run TensorFlow jobs with YuniKorn",source:"@site/docs/user_guide/workloads/run_tensorflow.md",sourceDirName:"user_guide/workloads",slug:"/user_guide/workloads/run_tf",permalink:"/docs/next/user_guide/workloads/run_tf",draft:!1,tags:[],version:"current",frontMatter:{id:"run_tf",title:"Run TensorFlow Jobs",description:"How to run TensorFlow jobs with YuniKorn",keywords:["tensorflow"]},sidebar:"docs",previous:{title:"Run Flink Jobs",permalink:"/docs/next/user_guide/workloads/run_flink"},next:{title:"Cluster",permalink:"/docs/next/api/cluster"}},u={},c=[{value:"Install training-operator",id:"install-training-operator",level:2},{value:"Prepare the docker image",id:"prepare-the-docker-image",level:2},{value:"Run a TensorFlow job",id:"run-a-tensorflow-job",level:2},{value:"Using Time-Slicing GPU",id:"using-time-slicing-gpu",level:2},{value:"Prerequisite",id:"prerequisite",level:3},{value:"Testing TensorFlow job with GPUs",id:"testing-tensorflow-job-with-gpus",level:3}],m={toc:c};function d(e){var n=e.components,l=(0,a.Z)(e,i);return(0,o.kt)("wrapper",(0,r.Z)({},m,l,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"This guide gives an overview of how to set up ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubeflow/training-operator"},"training-operator"),"\nand how to run a Tensorflow job with YuniKorn scheduler. The training-operator is a unified training operator maintained by\nKubeflow. It not only supports TensorFlow but also PyTorch, XGboots, etc."),(0,o.kt)("h2",{id:"install-training-operator"},"Install training-operator"),(0,o.kt)("p",null,"You can use the following command to install training operator in kubeflow namespace by default. If you have problems with installation,\nplease refer to ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubeflow/training-operator#installation"},"this doc")," for details."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'kubectl apply -k "github.com/kubeflow/training-operator/manifests/overlays/standalone?ref=v1.3.0"\n')),(0,o.kt)("h2",{id:"prepare-the-docker-image"},"Prepare the docker image"),(0,o.kt)("p",null,"Before you start running a TensorFlow job on Kubernetes, you'll need to build the docker image."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Download files from ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/apache/yunikorn-k8shim/tree/master/deployments/examples/tfjob"},"deployment/examples/tfjob")),(0,o.kt)("li",{parentName:"ol"},"To build this docker image with the following command")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"docker build -f Dockerfile -t kubeflow/tf-dist-mnist-test:1.0 .\n")),(0,o.kt)("h2",{id:"run-a-tensorflow-job"},"Run a TensorFlow job"),(0,o.kt)("p",null,"Here is a TFJob yaml for MNIST ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/apache/yunikorn-k8shim/blob/master/deployments/examples/tfjob/tf-job-mnist.yaml"},"example"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: kubeflow.org/v1\nkind: TFJob\nmetadata:\n  name: dist-mnist-for-e2e-test\n  namespace: kubeflow\nspec:\n  tfReplicaSpecs:\n    PS:\n      replicas: 2\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            applicationId: "tf_job_20200521_001"\n            queue: root.sandbox\n        spec:\n          schedulerName: yunikorn\n          containers:\n            - name: tensorflow\n              image: kubeflow/tf-dist-mnist-test:1.0\n    Worker:\n      replicas: 4\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            applicationId: "tf_job_20200521_001"\n            queue: root.sandbox\n        spec:\n          schedulerName: yunikorn\n          containers:\n            - name: tensorflow\n              image: kubeflow/tf-dist-mnist-test:1.0\n')),(0,o.kt)("p",null,"Create the TFJob"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"kubectl create -f deployments/examples/tfjob/tf-job-mnist.yaml\n")),(0,o.kt)("p",null,"You can view the job info from YuniKorn UI. If you do not know how to access the YuniKorn UI,\nplease read the document ",(0,o.kt)("a",{parentName:"p",href:"/docs/next/#access-the-web-ui"},"here"),"."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"tf-job-on-ui",src:t(8485).Z,width:"2442",height:"1308"})),(0,o.kt)("h2",{id:"using-time-slicing-gpu"},"Using Time-Slicing GPU"),(0,o.kt)("h3",{id:"prerequisite"},"Prerequisite"),(0,o.kt)("p",null,"To use Time-Slicing GPU your cluster must be configured to use GPUs and Time-Slicing GPUs."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Nodes must have GPUs attached."),(0,o.kt)("li",{parentName:"ul"},"Kubernetes version 1.24"),(0,o.kt)("li",{parentName:"ul"},"GPU drivers must be installed on the cluster"),(0,o.kt)("li",{parentName:"ul"},"Use the ",(0,o.kt)("a",{parentName:"li",href:"https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html"},"GPU Operator")," to automatically setup and manage the NVIDA software components on the worker nodes."),(0,o.kt)("li",{parentName:"ul"},"Set the Configuration of ",(0,o.kt)("a",{parentName:"li",href:"https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/gpu-sharing.html"},"Time-Slicing GPUs in Kubernetes"))),(0,o.kt)("p",null,"Once the GPU Operator and Time-Slicing GPUs is installed, check the status of the pods to ensure all the containers are running and the validation is complete :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"kubectl get pod -n gpu-operator\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"NAME                                                          READY   STATUS      RESTARTS       AGE\ngpu-feature-discovery-fd5x4                                   2/2     Running     0              5d2h\ngpu-operator-569d9c8cb-kbn7s                                  1/1     Running     14 (39h ago)   5d2h\ngpu-operator-node-feature-discovery-master-84c7c7c6cf-f4sxz   1/1     Running     0              5d2h\ngpu-operator-node-feature-discovery-worker-p5plv              1/1     Running     8 (39h ago)    5d2h\nnvidia-container-toolkit-daemonset-zq766                      1/1     Running     0              5d2h\nnvidia-cuda-validator-5tldf                                   0/1     Completed   0              5d2h\nnvidia-dcgm-exporter-95vm8                                    1/1     Running     0              5d2h\nnvidia-device-plugin-daemonset-7nzvf                          2/2     Running     0              5d2h\nnvidia-device-plugin-validator-gj7nn                          0/1     Completed   0              5d2h\nnvidia-operator-validator-nz84d                               1/1     Running     0              5d2h\n")),(0,o.kt)("p",null,"Verify that the time-slicing configuration is applied successfully :"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"kubectl describe node\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"Capacity:\n  nvidia.com/gpu:     16\n...\nAllocatable:\n  nvidia.com/gpu:     16\n...\n")),(0,o.kt)("h3",{id:"testing-tensorflow-job-with-gpus"},"Testing TensorFlow job with GPUs"),(0,o.kt)("p",null,"This section covers a workload test scenario to validate TFJob with Time-slicing GPU."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create a workload test file ",(0,o.kt)("inlineCode",{parentName:"p"},"tf-gpu.yaml")," as follows:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"vim tf-gpu.yaml\n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: "kubeflow.org/v1"\nkind: "TFJob"\nmetadata:\n  name: "tf-smoke-gpu"\n  namespace: kubeflow\nspec:\n  tfReplicaSpecs:\n    PS:\n      replicas: 1\n      template:\n        metadata:\n          creationTimestamp: \n          labels:\n            applicationId: "tf_job_20200521_001"\n        spec:\n          schedulerName: yunikorn\n          containers:\n            - args:\n                - python\n                - tf_cnn_benchmarks.py\n                - --batch_size=32\n                - --model=resnet50\n                - --variable_update=parameter_server\n                - --flush_stdout=true\n                - --num_gpus=1\n                - --local_parameter_device=cpu\n                - --device=cpu\n                - --data_format=NHWC\n              image: docker.io/kubeflow/tf-benchmarks-cpu:v20171202-bdab599-dirty-284af3\n              name: tensorflow\n              ports:\n                - containerPort: 2222\n                  name: tfjob-port\n              workingDir: /opt/tf-benchmarks/scripts/tf_cnn_benchmarks\n          restartPolicy: OnFailure\n    Worker:\n      replicas: 1\n      template:\n        metadata:\n          creationTimestamp: null\n          labels:\n            applicationId: "tf_job_20200521_001"\n        spec:\n          schedulerName: yunikorn\n          containers:\n            - args:\n                - python\n                - tf_cnn_benchmarks.py\n                - --batch_size=32\n                - --model=resnet50\n                - --variable_update=parameter_server\n                - --flush_stdout=true\n                - --num_gpus=1\n                - --local_parameter_device=cpu\n                - --device=gpu\n                - --data_format=NHWC\n              image: docker.io/kubeflow/tf-benchmarks-gpu:v20171202-bdab599-dirty-284af3\n              name: tensorflow\n              ports:\n                - containerPort: 2222\n                  name: tfjob-port\n              resources:\n                limits:\n                  nvidia.com/gpu: 2\n              workingDir: /opt/tf-benchmarks/scripts/tf_cnn_benchmarks\n          restartPolicy: OnFailure\n'))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create the TFJob"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"kubectl apply -f tf-gpu.yaml\n"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Verify that TFJob are running on YuniKorn:\n",(0,o.kt)("img",{alt:"tf-job-gpu-on-ui",src:t(3584).Z,width:"958",height:"698"}),"\nCheck the log of the pod:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"kubectl logs logs po/tf-smoke-gpu-worker-0 -n kubeflow\n")),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},".......\n..Found device 0 with properties:\n..name: NVIDIA GeForce RTX 3080 major: 8 minor: 6 memoryClockRate(GHz): 1.71\n\n.......\n..Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n.......\n")),(0,o.kt)("p",{parentName:"li"},"  ",(0,o.kt)("img",{alt:"tf-job-gpu-on-logs",src:t(60790).Z,width:"1434",height:"631"})))))}d.isMDXComponent=!0},60790:function(e,n,t){n.Z=t.p+"assets/images/tf-job-gpu-on-logs-45743e6e0d1330891435e70f544b0773.png"},3584:function(e,n,t){n.Z=t.p+"assets/images/tf-job-gpu-on-ui-f6dfde883fe4393624dfe813086a68d1.png"},8485:function(e,n,t){n.Z=t.p+"assets/images/tf-job-on-ui-e31edb85612822915f336b8cf9a25c3f.png"}}]);